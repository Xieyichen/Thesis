,title,abstract,bart_base,bart_cnn,bart_xsum,t5_small,gpt2,pegasus_xsum
18,#SupportTheCause: Identifying Motivations to Participate in Online Health Campaigns,"We consider the task of automatically identifying participantsâ€™ motivations in the public health campaign Movember and investigate the impact of the different motivations on the amount of campaign donations raised. Our classification scheme is based on the Social Identity Model of Collective Action (van Zomeren et al., 2008). We find that automatic classification based on Movember profiles is fairly accurate, while automatic classification based on tweets is challenging. Using our classifier, we find a strong relation between types of motivations and donations. Our study is a first step towards scaling-up collective action research methods.",<TITLE>Automatic Identification of Participants' Motives in the Public Health Campaign Movember<TITLE>Automatic Classification of Participants' Motives in the Public Health Campaign Movember<TITLE>Automatic Identification of Participants' Motives in the Movember Campaign<TITLE>Identifying Participants' Motives in the Public Health Campaign Movember<TITLE>Automatic Identification of Participants' Motives in Movember,<TITLE>Automatic Classification of Participants' Motivations in Movember Campaigns Using Collective Action Research and Social Identity Model of Collective Action<TITLE>Automatic Classification of Participants' Motivations in Movember Campaigns Using Collective Action Research and Social Identity Model of Movember<TITLE>Automatic Classification of Participants' Motivations in Movember Campaigns Using Social Identity Model of Collective Action Profiles and Twe<TITLE>Automatic Classification of Participants' Motivations in Movember Campaigns Using Social Identity Model of Collective Action Profiles and Automatic<TITLE>Automatic Classification of Participants' Motivations in Movember Campaigns Using Social Identity Model of Collective Action Profiles and Multi,<TITLE>Automatic classification of Movember participants' motivations and donations<TITLE>Automatic Classification of Movember Participants' Motives<TITLE>Automatic classification of Movember motivations and donations<TITLE>Automatic classification of motivations in Movember<TITLE>Automatic classification of Movember participants' motivations,<TITLE>Identifying Motivations in the Public Health Campaign Movember<TITLE>Identifying Motivations in Public Health Campaign Movember<TITLE>Automatic Identification of Motivations in Public Health Campaign Movember<TITLE>Identifying Motivations for Public Health Campaign Movember<TITLE>Automatic Classification for Public Health Campaign Movember,<TITLE> Automatic Identification of Participants' Motivations in the Campaign<TITLE> Automatic Identification of Participants' Motivations in Campaigns<TITLE> Automatic Identification of Political Motivations in Campaigns<TITLE> Automatic Characterization of Political Campaign Contributions<TITLE> Automatic Identification of Political Campaign Contributions,<TITLE>Identifying Participants' Motivatedness in the Movember Campaign<TITLE>Identifying Participants' Motivatedness in the Movember campaign<TITLE>Identifying Participants'  motivations in the Movember campaign<TITLE>Identifying Participants'  motivations for the Movember campaign<TITLE>Automatic Classification of Movember Participants'  motivations
74,Positional Encoding to Control Output Sequence Length,"Neural encoder-decoder models have been successful in natural language generation tasks. However, real applications of abstractive summarization must consider an additional constraint that a generated summary should not exceed a desired length. In this paper, we propose a simple but effective extension of a sinusoidal positional encoding (Vaswani et al., 2017) so that a neural encoder-decoder model preserves the length constraint. Unlike previous studies that learn length embeddings, the proposed method can generate a text of any length even if the target length is unseen in training data. The experimental results show that the proposed method is able not only to control generation length but also improve ROUGE scores.",<TITLE>A Simple but Effective Extension of a sinusoidal positional encoding for Abstractive Summarization<TITLE>A Simple but Effective Extension of a Sinusoidal positional encoding for Abstractive Summarization<TITLE>A Simple but Effective Extension of a sinusoidal positional encoding model for abstractive summarization<TITLE>A Simple but Effective Extension of a sinusoidal positional encoding for abstractive summarization<TITLE>Learning length embeddings for abstractive summarization with sinusoidal positional encoding.,<TITLE>A Simple and Effective Extension of Neural Encoder-Decoder Models for Abstractive Summarization Using a Sinusoidal Position<TITLE>A Simple and Effective Extension of Neural Encoder-Decoder Models for Abstractive Summarization Using a Sinusoidal Pos<TITLE>A Simple and Effective Extension of Neural Encoder-Decoder Models for Abstractive Summarization with Length Constraints.<TITLE>A Simple and Effective Extension of Neural Encoder-Decoder Models for Abstractive Summarization Using a Sinusoidal POS<TITLE>A Simple and Effective Extension of Neural Encoder-Decoder Models for Abstractive Summarization Using a Sinusoidal positional,<TITLE>Learning Length Embeddings for Abstractive Summarization with Neural Encoder-Decoder Models<TITLE>Learning Length Embeddings for Abstractive Summarization with Neural Encoder-Decoder Model<TITLE>Learning to Generate Text of Any Length with a Sinusoidal Positioning Encoder-Decoder<TITLE>Learning to Generate Text of Any Length with a Sinusoidal Positioning Encoding<TITLE>Learning to Generate Text of Any Length with a Sinusoidal Positioning Encoding,<TITLE>Sinusoidal Positional Encoding for Neural Language Generation<TITLE>Sinusoidal Positional Encoding for Neural Language Generating<TITLE>A Sinusoidal Positional Encoding for Neural Language Generation<TITLE>Sinusoidal Positional Encoding for Neural Language Generation<TITLE>A Sinusoidal Positional Encoding for Natural Language Generation,<TITLE> A Sinusoidal Neural Encoder-Decoder Model for Abstractive Summarization<TITLE> Learning Length Constraints for Abstractive Summarization<TITLE> A Sinusoidal Perceptron for Abstractive Summarization<TITLE> Simplifying Abstractive Summarization with Sinusoidal Parameter Encoders<TITLE> Simplifying Abstractive Summarization with Sinusoidal Position Representations,<TITLE>Learning Length Embeddings for Abstractive Summarization with Neural Decoding<TITLE>Learning Length Embeddings for Abstractive Summarization with Neural Networks<TITLE>Learning Length Embeddings for Abstractive Summarization<TITLE>Learning Length Embeddings for Neural Stream Summarization<TITLE>Learning Length Embeddings for Neural Summarization
